<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Exploração dos Clusters</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">FGV MBA</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-hand-holding-usd"></span>
     
    Cenário Proposto
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_about_the_data.html">Sobre os dados</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Análise Inicial</li>
    <li>
      <a href="02_data_preparation.html">Preparação dos Dados</a>
    </li>
    <li>
      <a href="03_data_exploration.html">Exploração dos Dados</a>
    </li>
    <li>
      <a href="04_clusters_exploration.html">Exploração dos Clusters</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-file-invoice-dollar"></span>
     
    Relatório Final
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="conclusion.html">Conclusão</a>
    </li>
    <li>
      <a href="references.html">Referências</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Exploração dos Clusters</h1>
<h4 class="date">Outubro de 2019</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#carregando-a-base-de-dados-processada"><span class="toc-section-number">1</span> Carregando a base de dados processada</a><ul>
<li><a href="#checando-a-necessidade-de-padronização-das-variáveis"><span class="toc-section-number">1.1</span> Checando a necessidade de padronização das variáveis</a></li>
</ul></li>
<li><a href="#métodos-de-clusterização"><span class="toc-section-number">2</span> Métodos de Clusterização</a><ul>
<li><a href="#agnes"><span class="toc-section-number">2.1</span> AGNES</a><ul>
<li><a href="#agnes-com-o-método-ward"><span class="toc-section-number">2.1.1</span> AGNES com o método <strong>ward</strong></a></li>
<li><a href="#agnes-com-o-método-average"><span class="toc-section-number">2.1.2</span> AGNES com o método <strong>average</strong></a></li>
</ul></li>
<li><a href="#k-means"><span class="toc-section-number">2.2</span> K-Means</a></li>
</ul></li>
</ul>
</div>

<div id="carregando-a-base-de-dados-processada" class="section level1">
<h1><span class="header-section-number">1</span> Carregando a base de dados processada</h1>
<p>Carregamos a base de dados alvo, previamente tratada durante os passos explicados na fase de <strong>Data Preparation</strong> (preparação de dados).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1">target_data &lt;-<span class="st"> </span><span class="kw">readRDS</span>(<span class="st">&#39;../data/processed/target_dataset.rds&#39;</span>)</a></code></pre></div>
<p>Em seguida selecionamos apenas as variáveis necessárias para o processo de clusterização.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="co"># subsetting the dataset</span></a>
<a class="sourceLine" id="cb2-2" title="2">target_data &lt;-<span class="st"> </span><span class="kw">select</span>(target_data, <span class="op">-</span><span class="kw">c</span>(idade, sexo, id))</a></code></pre></div>
<div id="checando-a-necessidade-de-padronização-das-variáveis" class="section level2">
<h2><span class="header-section-number">1.1</span> Checando a necessidade de padronização das variáveis</h2>
<p>Um procedimento necessário para datasets que contém variáveis em diferentes escalas é a padronização e normalização das escalas para o correto cálculo das métricas de distâncias utilizadas pelos algoritmos.</p>
<p>Porém para este conjunto de dados específico todas as variáveis estão na mesma escala, sendo assim não é necessária a padronização das vaiáveis.</p>
<p>Obteremos os mesmos resultados com as variáveis padronizadas ou não.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1"><span class="co"># target_data &lt;- sapply(target_data, scale)</span></a></code></pre></div>
<hr />
</div>
</div>
<div id="métodos-de-clusterização" class="section level1">
<h1><span class="header-section-number">2</span> Métodos de Clusterização</h1>
<div id="agnes" class="section level2">
<h2><span class="header-section-number">2.1</span> AGNES</h2>
<p>O método AGNES (Agglomerative Nesting) é um dos tipos mais comums de métyodos de cluster hierárquico usado para agrupar objetos em clusters com base em sua similaridade.</p>
<p>O algoritmo começa tratando cada observação como um cluster. Em seguida, pares de clusters são mesclados sucessivamente até que todos os clusters tenham sido mesclados em um grande cluster contendo todos os objetos.</p>
<p>O resultado é uma representação baseada em árvore dos objetos, chamada dendrograma.</p>
<p>Primeiramente iniciamos calculando a matriz de distancias das observações de nossa amostra</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1"><span class="co"># compute the dissimilarity matrix</span></a>
<a class="sourceLine" id="cb4-2" title="2">cluster_dist &lt;-<span class="st"> </span><span class="kw">dist</span>(target_data, <span class="dt">method =</span> <span class="st">&quot;euclidean&quot;</span>)</a>
<a class="sourceLine" id="cb4-3" title="3"></a>
<a class="sourceLine" id="cb4-4" title="4"><span class="co"># inspecting a samples of the dissimilarity matrix</span></a>
<a class="sourceLine" id="cb4-5" title="5"><span class="kw">as.matrix</span>(cluster_dist)[<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>]</a></code></pre></div>
<pre><code>##          1        2        3       4        5        6
## 1 0.000000 3.741657 3.316625 5.00000 4.898979 5.196152
## 2 3.741657 0.000000 5.385165 5.00000 5.656854 6.244998
## 3 3.316625 5.385165 0.000000 4.00000 3.605551 3.464102
## 4 5.000000 5.000000 4.000000 0.00000 3.000000 5.099020
## 5 4.898979 5.656854 3.605551 3.00000 0.000000 4.582576
## 6 5.196152 6.244998 3.464102 5.09902 4.582576 0.000000</code></pre>
<div id="agnes-com-o-método-ward" class="section level3">
<h3><span class="header-section-number">2.1.1</span> AGNES com o método <strong>ward</strong></h3>
<p>Com a matriz de distâncias calculadas no passo assima aplicamos o algoritimo AGNES com o método <strong>ward</strong> para obter o modelo de clusterização.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1"><span class="co"># applying the AGNES algorithm</span></a>
<a class="sourceLine" id="cb6-2" title="2">cluster_agnes_ward &lt;-<span class="st"> </span><span class="kw">agnes</span>(cluster_dist, </a>
<a class="sourceLine" id="cb6-3" title="3">                       <span class="dt">diss =</span> <span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb6-4" title="4">                       <span class="dt">metric =</span> <span class="st">&#39;euclidian&#39;</span>, </a>
<a class="sourceLine" id="cb6-5" title="5">                       <span class="dt">method =</span> <span class="st">&#39;ward&#39;</span>)</a>
<a class="sourceLine" id="cb6-6" title="6"></a>
<a class="sourceLine" id="cb6-7" title="7">cluster_agnes_ward</a></code></pre></div>
<pre><code>## Call:     agnes(x = cluster_dist, diss = TRUE, metric = &quot;euclidian&quot;, method = &quot;ward&quot;) 
## Agglomerative coefficient:  0.8321449 
## Order of objects:
##  [1]  1 25  3 21 22  7  8 11 28 12 17 30  6 24 27  2 16 10 18 20  4 26 15
## [24]  5 29  9 14 19 13 23
## Height (summary):
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   2.000   2.236   2.828   3.839   3.975  14.226 
## 
## Available components:
## [1] &quot;order&quot;  &quot;height&quot; &quot;ac&quot;     &quot;merge&quot;  &quot;diss&quot;   &quot;call&quot;   &quot;method&quot;</code></pre>
<p>Visualizando o dendrograma resultante da aplicação do algoritimo.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="kw">fviz_dend</span>(cluster_agnes_ward)</a></code></pre></div>
<p><img src="04_clusters_exploration_files/figure-html/generating_AGNES_viz_ward-1.png" width="100%" /></p>
<p>Analisando o dendrograma é possível verificar que 3 clusters parece ser a melhor escolha para o número de clusters utilizando o método <strong>ward</strong>, pois existe uma diferença significativa na altura das quebras das observações.</p>
<p>Abaixo visualizados o dendrograma para 3 clusters.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" title="1">cluster_size &lt;-<span class="st"> </span><span class="dv">3</span></a>
<a class="sourceLine" id="cb9-2" title="2"></a>
<a class="sourceLine" id="cb9-3" title="3"><span class="kw">fviz_dend</span>(cluster_agnes_ward, <span class="dt">k =</span> cluster_size)</a></code></pre></div>
<p><img src="04_clusters_exploration_files/figure-html/generating_AGNES_viz_2_ward-1.png" width="100%" /></p>
<p>Também podemos visualizar a classificação das observações utilizando as dois principais componentes da técnica de redução de dimensionalidade PCA (Principal Component Analysis).</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1"><span class="kw">fviz_cluster</span>(<span class="kw">list</span>(<span class="dt">data =</span> target_data, </a>
<a class="sourceLine" id="cb10-2" title="2">                  <span class="dt">cluster =</span> <span class="kw">cutree</span>(cluster_agnes_ward, <span class="dt">k =</span> cluster_size)),  </a>
<a class="sourceLine" id="cb10-3" title="3">             <span class="dt">show.clust.cent =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="04_clusters_exploration_files/figure-html/generating_AGNES_viz_3_ward-1.png" width="100%" /></p>
<p>Finalmente podemos analisar todas as métricas do cluster com o método <strong>ward</strong> utilizando a função <strong>cluster.stats</strong>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" title="1"><span class="kw">cluster.stats</span>(cluster_dist, <span class="kw">cutree</span>(cluster_agnes_ward, <span class="dt">k =</span> cluster_size))</a></code></pre></div>
<pre><code>## $n
## [1] 30
## 
## $cluster.number
## [1] 3
## 
## $cluster.size
## [1] 15  5 10
## 
## $min.cluster.size
## [1] 5
## 
## $noisen
## [1] 0
## 
## $diameter
## [1] 5.291503 4.472136 4.690416
## 
## $average.distance
## [1] 3.273186 3.116582 3.206379
## 
## $median.distance
## [1] 3.162278 2.995352 3.000000
## 
## $separation
## [1] 2.000000 3.605551 2.000000
## 
## $average.toother
## [1] 5.109357 5.824446 5.274204
## 
## $separation.matrix
##          [,1]     [,2]     [,3]
## [1,] 0.000000 3.605551 2.000000
## [2,] 3.605551 0.000000 4.123106
## [3,] 2.000000 4.123106 0.000000
## 
## $ave.between.matrix
##          [,1]     [,2]     [,3]
## [1,] 0.000000 5.485469 4.921301
## [2,] 5.485469 0.000000 6.332911
## [3,] 4.921301 6.332911 0.000000
## 
## $average.between
## [1] 5.331822
## 
## $average.within
## [1] 3.224816
## 
## $n.between
## [1] 275
## 
## $n.within
## [1] 160
## 
## $max.diameter
## [1] 5.291503
## 
## $min.separation
## [1] 2
## 
## $within.cluster.ss
## [1] 147.6667
## 
## $clus.avg.silwidths
##         1         2         3 
## 0.3098483 0.4280708 0.3377009 
## 
## $avg.silwidth
## [1] 0.3388362
## 
## $g2
## NULL
## 
## $g3
## NULL
## 
## $pearsongamma
## [1] 0.7219382
## 
## $dunn
## [1] 0.3779645
## 
## $dunn2
## [1] 1.50352
## 
## $entropy
## [1] 1.011404
## 
## $wb.ratio
## [1] 0.6048244
## 
## $ch
## [1] 16.69063
## 
## $cwidegap
## [1] 2.828427 2.645751 2.645751
## 
## $widestgap
## [1] 2.828427
## 
## $sindex
## [1] 2.333333
## 
## $corrected.rand
## NULL
## 
## $vi
## NULL</code></pre>
</div>
<div id="agnes-com-o-método-average" class="section level3">
<h3><span class="header-section-number">2.1.2</span> AGNES com o método <strong>average</strong></h3>
<p>Com a matriz de distâncias calculadas no passo assima aplicamos o algoritimo AGNES com o método <strong>average</strong> para obter o modelo de clusterização.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1"><span class="co"># applying the AGNES algorithm</span></a>
<a class="sourceLine" id="cb13-2" title="2">cluster_agnes_average &lt;-<span class="st"> </span><span class="kw">agnes</span>(cluster_dist, </a>
<a class="sourceLine" id="cb13-3" title="3">                       <span class="dt">diss =</span> <span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb13-4" title="4">                       <span class="dt">metric =</span> <span class="st">&#39;euclidian&#39;</span>, </a>
<a class="sourceLine" id="cb13-5" title="5">                       <span class="dt">method =</span> <span class="st">&#39;average&#39;</span>)</a>
<a class="sourceLine" id="cb13-6" title="6"></a>
<a class="sourceLine" id="cb13-7" title="7">cluster_agnes_average</a></code></pre></div>
<pre><code>## Call:     agnes(x = cluster_dist, diss = TRUE, metric = &quot;euclidian&quot;, method = &quot;average&quot;) 
## Agglomerative coefficient:  0.5960608 
## Order of objects:
##  [1]  1 25  3 21 22 11 28 12 17 30  7  8  6 24 27  4 26 15  5 29  9 14 19
## [24] 13 23  2 16 10 18 20
## Height (summary):
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   2.000   2.236   2.646   2.872   3.112   5.824 
## 
## Available components:
## [1] &quot;order&quot;  &quot;height&quot; &quot;ac&quot;     &quot;merge&quot;  &quot;diss&quot;   &quot;call&quot;   &quot;method&quot;</code></pre>
<p>Visualizando o dendrograma resultante da aplicação do algoritimo.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" title="1"><span class="kw">fviz_dend</span>(cluster_agnes_average)</a></code></pre></div>
<p><img src="04_clusters_exploration_files/figure-html/generating_AGNES_viz_average-1.png" width="100%" /></p>
<p>Analisando o dendrograma para o número de clusters utilizando o método <strong>average</strong>, não fica muito evidente qual o melhor “corte” de número de clusters. Ainda assim, é possível notar que existe uma melhor distinção de grupos em 3 clusters.</p>
<p>Abaixo visualizados o dendrograma para 3 clusters.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1">cluster_size &lt;-<span class="st"> </span><span class="dv">3</span></a>
<a class="sourceLine" id="cb16-2" title="2"></a>
<a class="sourceLine" id="cb16-3" title="3"><span class="kw">fviz_dend</span>(cluster_agnes_average, <span class="dt">k =</span> cluster_size)</a></code></pre></div>
<p><img src="04_clusters_exploration_files/figure-html/generating_AGNES_viz_2_average-1.png" width="100%" /></p>
<p>Também podemos visualizar a classificação das observações utilizando as dois principais componentes da técnica de redução de dimensionalidade PCA (Principal Component Analysis).</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" title="1"><span class="kw">fviz_cluster</span>(<span class="kw">list</span>(<span class="dt">data =</span> target_data, </a>
<a class="sourceLine" id="cb17-2" title="2">                  <span class="dt">cluster =</span> <span class="kw">cutree</span>(cluster_agnes_average, <span class="dt">k =</span> cluster_size)),  </a>
<a class="sourceLine" id="cb17-3" title="3">             <span class="dt">show.clust.cent =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="04_clusters_exploration_files/figure-html/generating_AGNES_viz_3_average-1.png" width="100%" /></p>
<p>Finalmente podemos analisar todas as métricas do cluster com o método <strong>average</strong> utilizando a função <strong>cluster.stats</strong>.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1"><span class="kw">cluster.stats</span>(cluster_dist, <span class="kw">cutree</span>(cluster_agnes_average, <span class="dt">k =</span> cluster_size))</a></code></pre></div>
<pre><code>## $n
## [1] 30
## 
## $cluster.number
## [1] 3
## 
## $cluster.size
## [1] 15  5 10
## 
## $min.cluster.size
## [1] 5
## 
## $noisen
## [1] 0
## 
## $diameter
## [1] 5.291503 4.472136 4.690416
## 
## $average.distance
## [1] 3.273186 3.116582 3.206379
## 
## $median.distance
## [1] 3.162278 2.995352 3.000000
## 
## $separation
## [1] 2.000000 3.605551 2.000000
## 
## $average.toother
## [1] 5.109357 5.824446 5.274204
## 
## $separation.matrix
##          [,1]     [,2]     [,3]
## [1,] 0.000000 3.605551 2.000000
## [2,] 3.605551 0.000000 4.123106
## [3,] 2.000000 4.123106 0.000000
## 
## $ave.between.matrix
##          [,1]     [,2]     [,3]
## [1,] 0.000000 5.485469 4.921301
## [2,] 5.485469 0.000000 6.332911
## [3,] 4.921301 6.332911 0.000000
## 
## $average.between
## [1] 5.331822
## 
## $average.within
## [1] 3.224816
## 
## $n.between
## [1] 275
## 
## $n.within
## [1] 160
## 
## $max.diameter
## [1] 5.291503
## 
## $min.separation
## [1] 2
## 
## $within.cluster.ss
## [1] 147.6667
## 
## $clus.avg.silwidths
##         1         2         3 
## 0.3098483 0.4280708 0.3377009 
## 
## $avg.silwidth
## [1] 0.3388362
## 
## $g2
## NULL
## 
## $g3
## NULL
## 
## $pearsongamma
## [1] 0.7219382
## 
## $dunn
## [1] 0.3779645
## 
## $dunn2
## [1] 1.50352
## 
## $entropy
## [1] 1.011404
## 
## $wb.ratio
## [1] 0.6048244
## 
## $ch
## [1] 16.69063
## 
## $cwidegap
## [1] 2.828427 2.645751 2.645751
## 
## $widestgap
## [1] 2.828427
## 
## $sindex
## [1] 2.333333
## 
## $corrected.rand
## NULL
## 
## $vi
## NULL</code></pre>
</div>
</div>
<div id="k-means" class="section level2">
<h2><span class="header-section-number">2.2</span> K-Means</h2>
<p>O método de classificação por K-means é um dos algoritmos de aprendizado de máquina não supervisionados mais simples e populares.</p>
<p>O algoritmo começa com um primeiro grupo de centroides selecionados aleatoriamente, que são usados como pontos de partida para cada cluster e, em seguida, executa cálculos iterativos para otimizar as posições dos centroides.</p>
<p>Para cada iteração o algoritmo calcula a métrica de distância selecionada entre cada observação e o centroide classificando cada observação ao cluster cujo centroide está mais próximo.</p>
<p>Ele interrompe a criação e otimização de clusters quando:</p>
<ol style="list-style-type: decimal">
<li><p>Os centroides se estabilizaram - não há alteração em seus valores porque o agrupamento foi bem-sucedido.</p></li>
<li><p>O número definido de iterações foi alcançado.</p></li>
</ol>
<p>O parâmetro mais importante para o método de k-means é a quantidade de clusters que o algoritmo irá utilizar.</p>
<p>Para encontrar a melhor quantidade de clusters podemos observar o comportamento de duas métricas, withinss e betweenss, que medem as distâncias intra-cluster e inter-clusters de cada observação e centroide dos clusters.</p>
<p>A melhor quantidade de k é dada no ponto onde existe uma estabilização entre as métricas.</p>
<p>Iremos utilizar uma função customizada por nós para definir a melhor quantidade de clusters a utilizar, basicamente definimos o melhor k como sendo aquele onde existe a menor diferença absoluta entre as métricas de withinss e betweenss.</p>
<p>Mais detalhes sobre a função podem ser encontrados na sessão de preparação de dados desta pagina.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" title="1"><span class="kw">find_best_k_kmeans</span>(target_data, <span class="dt">k_limit =</span> <span class="dv">29</span>, <span class="dt">nstart =</span> <span class="dv">100</span>)<span class="op">$</span>plot</a></code></pre></div>
<p><img src="04_clusters_exploration_files/figure-html/generating_kmeans_best_k-1.png" width="100%" /></p>
<p>Em seguida aplicamos o algoritmo k-means utilizando a melhor quantidade de clusters retornada pela nossa função.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1">cluster_size &lt;-<span class="st"> </span><span class="kw">find_best_k_kmeans</span>(target_data, <span class="dt">k_limit =</span> <span class="dv">29</span>, <span class="dt">nstart =</span> <span class="dv">100</span>)<span class="op">$</span>best_k</a>
<a class="sourceLine" id="cb21-2" title="2"></a>
<a class="sourceLine" id="cb21-3" title="3">cluster_kmeans &lt;-<span class="st"> </span><span class="kw">kmeans</span>(target_data, cluster_size, <span class="dt">nstart =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb21-4" title="4"></a>
<a class="sourceLine" id="cb21-5" title="5">cluster_kmeans</a></code></pre></div>
<pre><code>## K-means clustering with 3 clusters of sizes 5, 10, 15
## 
## Cluster means:
##   aceitar_convite gostar_doces emocionar conhecer_pessoas diversao_amigos
## 1        4.400000          2.6       4.8         2.600000        2.200000
## 2        1.800000          2.1       1.4         2.600000        2.400000
## 3        3.933333          3.8       2.4         3.933333        4.266667
##   gostar_fotos cansar_cerimonia casamento_civil
## 1          3.2         1.600000        4.400000
## 2          2.6         4.300000        2.000000
## 3          3.2         4.066667        2.933333
## 
## Clustering vector:
##  [1] 3 1 3 2 2 3 3 3 2 1 3 3 2 2 2 1 3 1 2 1 3 3 2 3 3 2 3 3 2 3
## 
## Within cluster sum of squares by cluster:
## [1] 20.40000 48.20000 79.06667
##  (between_SS / total_SS =  55.3 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;    
## [5] &quot;tot.withinss&quot; &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;        
## [9] &quot;ifault&quot;</code></pre>
<p>Assim como fizemos para o método AGNES podemos visualizar a classificação, para o método k-means, das observações utilizando as dois principais componentes da técnica de redução de dimensionalidade PCA (Principal Component Analysis).</p>
<p>Observamos que ambos os métodos classificaram as observações nos mesmos clusters.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1"><span class="co"># Visualizing clusters</span></a>
<a class="sourceLine" id="cb23-2" title="2"></a>
<a class="sourceLine" id="cb23-3" title="3"><span class="kw">fviz_cluster</span>(<span class="kw">list</span>(<span class="dt">data =</span> target_data, <span class="dt">cluster =</span> cluster_kmeans<span class="op">$</span>cluster),</a>
<a class="sourceLine" id="cb23-4" title="4">             <span class="dt">show.clust.cent =</span> T)</a></code></pre></div>
<p><img src="04_clusters_exploration_files/figure-html/generating_kmeans_viz-1.png" width="100%" /></p>
<p>Abaixo as métricas gerais do método de classificação k-means aplicado a este dataset.</p>
<p>Observamos que como a ambos os métodos AGNES e k-means obtém exatamente as mesmas métricas pois ambos os métodos classificaram os dados nos mesmos clusters.</p>
<p>A única diferença são os números de identificação associados a cada cluster.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" title="1"><span class="kw">cluster.stats</span>(cluster_dist, cluster_kmeans<span class="op">$</span>cluster)</a></code></pre></div>
<pre><code>## $n
## [1] 30
## 
## $cluster.number
## [1] 3
## 
## $cluster.size
## [1]  5 10 15
## 
## $min.cluster.size
## [1] 5
## 
## $noisen
## [1] 0
## 
## $diameter
## [1] 4.472136 4.690416 5.291503
## 
## $average.distance
## [1] 3.116582 3.206379 3.273186
## 
## $median.distance
## [1] 2.995352 3.000000 3.162278
## 
## $separation
## [1] 3.605551 2.000000 2.000000
## 
## $average.toother
## [1] 5.824446 5.274204 5.109357
## 
## $separation.matrix
##          [,1]     [,2]     [,3]
## [1,] 0.000000 4.123106 3.605551
## [2,] 4.123106 0.000000 2.000000
## [3,] 3.605551 2.000000 0.000000
## 
## $ave.between.matrix
##          [,1]     [,2]     [,3]
## [1,] 0.000000 6.332911 5.485469
## [2,] 6.332911 0.000000 4.921301
## [3,] 5.485469 4.921301 0.000000
## 
## $average.between
## [1] 5.331822
## 
## $average.within
## [1] 3.224816
## 
## $n.between
## [1] 275
## 
## $n.within
## [1] 160
## 
## $max.diameter
## [1] 5.291503
## 
## $min.separation
## [1] 2
## 
## $within.cluster.ss
## [1] 147.6667
## 
## $clus.avg.silwidths
##         1         2         3 
## 0.4280708 0.3377009 0.3098483 
## 
## $avg.silwidth
## [1] 0.3388362
## 
## $g2
## NULL
## 
## $g3
## NULL
## 
## $pearsongamma
## [1] 0.7219382
## 
## $dunn
## [1] 0.3779645
## 
## $dunn2
## [1] 1.50352
## 
## $entropy
## [1] 1.011404
## 
## $wb.ratio
## [1] 0.6048244
## 
## $ch
## [1] 16.69063
## 
## $cwidegap
## [1] 2.645751 2.645751 2.828427
## 
## $widestgap
## [1] 2.828427
## 
## $sindex
## [1] 2.333333
## 
## $corrected.rand
## NULL
## 
## $vi
## NULL</code></pre>
<p>Na sessão de conclusão responderemos todas as perguntas iniciais do trabalho.</p>
<p>Finalizando o processo vamos salvar a classificaçao de cada cluster em disco para utilizarmos no conclusão da atividade</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
